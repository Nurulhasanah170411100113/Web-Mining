# Web-Mining
	Web Scraping
Apa Itu Web Scraping?
  Web scraping adalah metode yang sangat berguna dalam bisnis online, baik itu untuk riset pasar, riset kompetitor, atau mencari leads. Namun, manfaatnya lebih dari sekedar itu. 
  Dalam menjalankan bisnis online, pastinya Anda pernah mendata kompetitor-kompetitor Anda beserta informasi penting mengenai produk atau layanan mereka. Kemudian, Anda menyimpan data tersebut di dalam sebuah spreadsheet — baik itu menggunakan Microsoft Excel, Google Sheet atau aplikasi sejenisnya. Proses inilah yang disebut sebagai web scraping. Dengan kata lain, web scraping dapat didefinisikan sebagai proses pengambilan data dari sebuah website.
Secara umum, ada dua cara yang bisa Anda gunakan untuk melakukannya :
•	Manual — metode di mana Anda menyalin data dengan cara copy paste dari sebuah website
•	Otomatis — metode yang menggunakan koding, aplikasi, atau extension browser.

Teknik-Teknik Web Scraping
Web scraping kini dimudahkan dengan bantuan browser extension dan aplikasi. Namun, hasilnya masih belum sebaik cara manual dan koding. Dalam artikel ini  kami akan membahas enam teknik web scraping yang umum dilakukan, yaitu:
•	Menyalin data secara manual
•	Menggunakan regular expression
•	Parsing HTML
•	Menganalisa DOM
•	Menggunakan XPath
•	Menggunakan Google Sheet
1. Menyalin Data secara Manual
Cara web scraping yang paling sederhana adalah menyalin data website secara manual. Karena Anda harus mengambil dan menyimpan informasi yang diperlukan satu per satu, teknik ini memakan waktu lama.
Akan tetapi, metode ini paling efektif dari segi pencarian data. Tidak seperti tool atau bot, Anda sudah tahu letak informasi yang ingin disalin dari suatu website. Dengan demikian, hasil web scraping dengan cara ini sangat akurat.
Teknik manual ini dianjurkan jika jumlah website atau blog yang ingin Anda saring terbatas.
2. Menggunakan Regular Expression
Regular expression adalah baris kode yang digunakan dalam algoritma pencarian untuk menemukan tipe data tertentu dari sebuah file. Dalam konteks web scraping, file yang dimaksud adalah file-file penunjang sebuah website.
Keuntungan utama menggunakan regular expression untuk web scraping adalah konsistensi syntaxnya di dalam berbagai bahasa pemrograman. Oleh karena itu, teknik ini sangat fleksibel.
Ditambah lagi, regular expression dapat digunakan untuk mencari data berdasarkan jenisnya, seperti nama produk, harga, dan alamat email.
3. Parsing HTML
Pada dasarnya, parsing HTML adalah metode yang dilakukan dengan mengirimkan HTTP request kepada server yang menyimpan data website yang datanya ingin Anda ekstrak.
Dengan teknik ini, Anda dapat melakukan web scraping tidak hanya pada halaman website yang bersifat statis, tetapi juga dinamis. Selain itu, parsing HTML juga memungkinkan Anda untuk menyalin data dalam jumlah yang besar dalam waktu singkat.
Sayangnya, parsing HTML dapat dicegah dengan proteksi website. Tak hanya itu, Anda bisa diblokir dari suatu situs jika terlalu sering melakukan teknik ini.
4. Menganalisa DOM
DOM atau document object model adalah representasi struktur sebuah halaman website yang ditulis dengan HTML.
Ketika melakukan parsing HTML, DOM dari halaman yang ingin diekstrak datanya akan dimuat terlebih dahulu. Untungnya, DOM juga membawa data yang ada pada file HTML.
Oleh karena itu, analisa DOM bisa dijadikan alternatif untuk melakukan web scraping terhadap halaman situs dinamis jika parsing HTML tidak membuahkan hasil.
Untuk membantu proses ini, Anda bisa mencari informasi yang diinginkan dengan regular expression (poin nomor 2).
5. Menggunakan XPath
XPath adalah bahasa query yang digunakan untuk memilih node dari struktur file XML dan HTML.
Implementasinya tidak jauh berbeda dengan analisa DOM. Anda menggunakannya untuk mencari data dari struktur file penunjang halaman.
Selain itu, XPath juga dapat digunakan untuk mencari data pada elemen teks dalam file XML dan HTML. Dengan demikian, teknik web scraping ini bisa Anda pilih ketika analisa DOM kurang efektif.
6. Menggunakan Google Sheet
Google Sheet adalah aplikasi web milik Google yang biasanya digunakan untuk membuat spreadsheet. Akan tetapi, aplikasi ini ternyata juga bisa digunakan untuk melakukan web scraping dengan mudah.
Di samping Google Sheet, Anda hanya memerlukan browser yang memiliki fitur inspect element. Setelah itu, tinggal mengopi expression XPath dari elemen halaman website yang datanya ingin Anda salin ke dalam command IMPORTXML yang ada di Google Sheet.
Manfaat Web Scraping
Seperti yang telah disebutkan di awal artikel, penggunaan web scraping menawarkan beberapa manfaat. Berikut ini adalah empat keuntungan utamanya.
Mendapatkan Leads
Dalam berburu leads untuk bisnis baru, tidak ada salahnya jika Anda mendekati follower akun media sosial kompetitor. Bahkan, kemungkinan mereka berkemungkinan besar untuk tertarik dengan produk atau layanan Anda.
Nah, web scraping dilakukan untuk memudahkan proses ini. Dengannya, Anda bisa menyalin daftar follower masing-masing kompetitor dan mengopi alamat email mereka. Tak lupa, Anda dapat menggunakan data lain seperti demografi follower untuk jadi bahan segmentasi.
Membandingkan Ulasan dalam Jumlah Besar
Memiliki pemahaman yang mendalam atas kebutuhan konsumen adalah sebuah kewajiban jika Anda ingin memenangkan hati mereka. Dengan mengantongi pengetahuan tersebut, Anda dapat meningkatkan layanan atau menciptakan produk yang solutif.
Untuk dapat melakukannya, Anda bisa membaca ulasan-ulasan konsumen tentang produk dan layanan kompetitor, baik itu di blog review, forum, maupun marketplace online.
Dengan adanya web scraping, usaha Anda untuk mendokumentasikan data tersebut akan dipermudah dan dipercepat.
Optimasi Harga Produk atau Layanan
Menentukan harga bagi layanan atau produk Anda memang tidak mudah. Ada banyak hal yang perlu diperhatikan, termasuk biaya produksi, SDM, brand positioning, dan harga yang ditawarkan kompetitor.
Setidaknya, web scraping membantu Anda untuk mengumpulkan harga produk dan layanan bisnis pesaing. Dengan demikian, Anda dapat memperhatikan tren harga yang ada di pasar.
Mencari Informasi sebuah Perusahaan
Suatu saat mungkin Anda perlu bekerjasama dengan pemilik bisnis lain. Namun, Anda ingin memastikan bahwa usaha tersebut dapat dipercaya.
Nah, Anda bisa melakukan “investigasi” mandiri terhadap usaha tersebut di internet dengan bantuan web scraping.
Kendala dalam Melakukan Web Scraping
Meskipun web scraping merupakan teknik yang sangat membantu dalam ekstraksi data situs, ada juga hal-hal yang menjadi halangan dalam implementasinya. Setidaknya, lima hal di bawah ini perlu Anda ingat jika ingin melakukannya:
•	Tidak ada teknik web scraping yang 100% efektif — Metode web scraping, baik yang dibahas dalam artikel ini maupun yang menggunakan aplikasi, tidak ada yang sempurna.
•	Data yang didapat tidak selalu rapi — Apapun metode yang Anda pakai pasti akan menyisakan teks-teks yang tidak diinginkan, seperti tag HTML. Oleh karenanya, Anda masih harus merapikan data hasil web scraping.
•	Pemahaman tentang struktur halaman website tetap menjadi kewajiban — Tidak semua teknik web scraping memerlukan koding. Akan tetapi, Anda tetap harus memahami HTML dan CSS. Ini dibutuhkan ketika Anda mencari letak data yang ingin diekstrak menggunakan fitur inspect element pada browser.
•	Akses Anda ke suatu website dapat diblokir — terlalu sering melakukan web scraping terhadap suatu website dapat menyebabkan IP Anda diblokir oleh adminnya.
•	Tidak semua website mudah diekstrak datanya — Web developer akan selalu memperbarui websitenya, baik dari segi kode maupun struktur halamannya, untuk alasan keamanan. Maka dari itu, jangan heran ketika Anda menemui situs yang datanya susah diekstrak.

	Code
	Text Preprocessing
Berdasarkan ketidak teraturan struktur data teks, maka proses sistem temu kembali informasi ataupun text mining memerlukan beberapa tahap awal yang pada intinya adalah mempersiapkan agar teks dapat diubah menjadi lebih terstruktur. Salah satu implementasi dari text mining adalah tahap Text Preprocessing.
Tahap Text Preprocessing adalah tahapan dimana aplikasi melakukan seleksi data yang akan diproses pada setiap dokumen. Proses preprocessing ini meliputi (1) case folding, (2) tokenizing, (3) filtering, dan (4) stemming
 
1. Case Folding
Tidak semua dokumen teks konsisten dalam penggunaan huruf kapital. Oleh karena itu, peran Case Folding dibutuhkan dalam mengkonversi keseluruhan teks dalam dokumen menjadi suatu bentuk standar (biasanya huruf kecil atau lowercase). Sebagai contoh, user yang ingin mendapatkan informasi “KOMPUTER” dan mengetik “KOMPOTER”, “KomPUter”, atau “komputer”, tetap diberikan hasil retrieval yang sama yakni “komputer”. Case folding adalah mengubah semua huruf dalam dokumen menjadi huruf kecil. Hanya huruf ‘a’ sampai dengan ‘z’ yang diterima. Karakter selain huruf dihilangkan dan dianggap delimiter.
 
2. Tokenizing
Tahap Tokenizing adalah tahap pemotongan string input berdasarkan tiap kata yang menyusunnya. Contoh dari tahap ini dapat dilihat pada gambar dibawah ini.
 
Tokenisasi secara garis besar memecah sekumpulan karakter dalam suatu teks ke dalam satuan kata, bagaimana membedakan karakter-karakter tertentu yang dapat diperlakukan sebagai pemisah kata atau bukan.
Sebagai contoh karakter whitespace, seperti enter, tabulasi, spasi dianggap sebagai pemisah kata. Namun untuk karakter petik tunggal (‘), titik (.), semikolon (;), titk dua (:) atau lainnya, dapat memiliki peran yang cukup banyak sebagai pemisah kata.
 Dalam memperlakukan karakter-karakter dalam teks sangat tergantung pada kontek aplikasi yang dikembangkan. Pekerjaan tokenisasi ini akan semakin sulit jika juga harus memperhatikan struktur bahasa (grammatikal).
 3. Filtering
Tahap Filtering adalah tahap mengambil kata-kata penting dari hasil token. Bisa menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting). Stoplist/stopword adalah kata-kata yang tidak deskriptif yang dapat dibuang dalam pendekatan bag-of-words. Contoh stopwords adalah “yang”, “dan”, “di”, “dari” dan seterusnya. Data stopword dapat diambil dari jurnal Fadillah Z Tala berjudul ”A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia”.
 
Kata-kata seperti “dari”, “yang”, “di”, dan “ke” adalah beberapa contoh kata-kata yang berfrekuensi tinggi dan dapat ditemukan hampir dalam setiap dokumen (disebut sebagai stopword). Penghilangan stopword ini dapat mengurangi ukuran index dan waktu pemrosesan. Selain itu, juga dapat mengurangi level noise.
Namun terkadang stopping tidak selalu meningkatkan nilai retrieval. Pembangunan daftar stopword (disebut stoplist) yang kurang hati-hati dapat memperburuk kinerja sistem Information Retrieval (IR). Belum ada suatu kesimpulan pasti bahwa penggunaan stopping akan selalu meningkatkan nilai retrieval, karena pada beberapa penelitian, hasil yang didapatkan cenderung bervariasi.
 4. Stemming
Pembuatan indeks dilakukan karena suatu dokumen tidak dapat dikenali langsung oleh suatu Sistem Temu Kembali Informasi atau Information Retrieval System (IRS). Oleh karena itu, dokumen tersebut terlebih dahulu perlu dipetakan ke dalam suatu representasi dengan menggunakan teks yang berada di dalamnya.
 Teknik Stemming diperlukan selain untuk memperkecil jumlah indeks yang berbeda dari suatu dokumen, juga untuk melakukan pengelompokan kata-kata lain yang memiliki kata dasar dan arti yang serupa namun memiliki bentuk atau form yang berbeda karena mendapatkan imbuhan yang berbeda.
 Sebagai contoh kata bersama, kebersamaan, menyamai, akan distem ke root word-nya yaitu “sama”. Namun, seperti halnya stopping, kinerja stemming juga bervariasi dan sering tergantung pada domain bahasa yang digunakan.
Proses stemming pada teks berbahasa Indonesia berbeda dengan stemming pada teks berbahasa Inggris. Pada teks berbahasa Inggris, proses yang diperlukan hanya proses menghilangkan sufiks. Sedangkan pada teks berbahasa Indonesia semua kata imbuhan baik itu sufiks dan prefiks juga dihilangkan.
 
	Klasterisasi 
Konsep dari pengelompokkan (clustering) yaitu dengan melakukan proses segmentasi atau pemecahan data ke dalam sejumlah kelompok (cluster) berdasarkan karakteristik tertentu yang diinginkan. Dalam proses pengerjaannya, label dari setiap data belum diketahui, dan dengan pengelompokkan diharapkan dapat diketahui kelompok data untuk kemudian diberi label yang sesuai dengan keinginan. 

Tujuan pengelompokkan (clustering) data dapat dibedakan menjadi dua, yaitu pengelompokkan untuk pemahaman dan pengelompokkan untuk penggunaan. Jika tujuannya untuk pemahaman, kelompok yang terbentuk harus menangkap struktur alami data, biasanya proses pengelompokkan dalam tujuan ini hanya sebagai proses awalan untuk kemudian dilanjutkan dengan pekerjaan lain seperti peringkasan (summarization), pelabelan kelas pada setiap kelompok yang kemudian digunakan sebagai data latih dalam proses klasifikasi Ada banyak jenis-jenis metode pengelompokan yang sudah dikembangkan. Masing-masing metode memiliki karakter, kelebihan, dan kekurangan. Menurut strukturnya, pengelompokan dibagi menjadi dua, yaitu pengelompokkan hierarki dan partitioning. Pengelompokkan hierarki memiliki satu data tunggal yang bisa dianggap sebagai sebuah kelompok, dua atau lebih kelompok kecil dapat bergabung menjadi sebuah kelompok besar dan begitu seterusnya hingga semua data dapat bergabung menjadi sebuah kelompok. Di sisi lain, metode pengelompokkan partitioning membagi set data ke dalam sejumlah kelompok yang tidak overlap antara satu kelompok dengan kelompok yang lain. Dalam hal ini metode tersebut yaitu k-means. 

•	K-Means Clustering 
K-means merupakan salah satu metode pengelompokkan secara partitioning yang berusaha mempartisi data yang ada ke dalam bentuk dua atau lebih kelompok. Metode ini mempartisi sebuah data yang ada ke dalam suatu kelompok sehingga data yang berkarakteristik sama akan dimasukkan ke dalam satu kelompok yang sama dan data yang berkarakteristik berbeda dikelompokkan ke dalam kelompok yang lain [8].Tujuan pengelompokkan data ini adalah untuk meminimalkan fungsi objektif yang di set dalam proses pengelompokkan, yang pada umumnya berusaha meminimalkan variasi di dalam suatu kelompok dan memaksimalkan variasi antar kelompok. Adapun pengelompokkan data dengan metode k-means ini secara umum dilakukan dengan algoritma seperti Algoritma 

Untuk menghitung jarak similaritas antar objek pada metode k-means diperlukan algoritma euclidean distance seperti Algoritma. 
 
Cara kerja pada metode k-means dengan menggunakan algoritma euclidean distance sebagai fungsi jarak, yaitu yang pertama menentukan jumlah cluster yang ingin dibentuk misalkan 3, 5, atau 7 cluster. Setelah itu menentukan titik pusat atau centroid awal secara acak. Setelah centroid ditentukan maka hitung jarak setiap data ke masing-masing centroid dengan menggunakan rumus euclidean distance. 

Apabila sudah diketahui nilai jarak setiap data, maka mengelompokkan setiap data tersebut berdasarkan jarak yang terdekat dari centroid. Apabila masih terdapat data yang belum masuk ke dalam kelompok cluster, maka ulangi proses dari menentukan centroid hingga tidak ada lagi data yang tidak masuk ke dalam kelompok cluster. Adapun contoh perhitungan pada metode k-means dengan data seperti pada Tabel 2.1 dapat ditinjau sebagai berikut : 

Misalkan titik pusat ditentukan sesuai pada tabel diatas dengan pembentukan 3 cluster. 
kemudian pilih data yang akan dihitung jarak datanya misalkan data “Administrator” dengan bobot kata sebesar 1,6. Lalu masukkan kedalam rumus euclidean distance, sebagai contoh akan dihitung jarak dari data “Administrator” ke centroid cluster pertama yaitu data “Absensi” dengan persamaan : 
Dari hasil perhitungan diatas di dapatkan hasil bahwa jarak data “Administrator” dengan centroid cluster yang pertama adalah 0,34. 

jarak dari data “Administrator” ke centroid cluster kedua yaitu data “Accelerometer” dengan persamaan : 
Dari hasil perhitungan diatas di dapatkan hasil bahwa jarak data “Administrator” dengan centroid cluster yang kedua adalah 0,47. 

jarak dari data “Administrator” ke centroid cluster ketiga yaitu data “Acara” dengan persamaan : 
Dari hasil perhitungan diatas di dapatkan hasil bahwa jarak data “Administrator” dengan  centroid  cluster  yang  ketiga  adalah  0,48.  

Berdasarkan  hasil  ketiga perhitungan  di  atas  dapat  disimpulkan  bahwa  jarak  data  “Administrator”  yang paling dengan dengan centroid adalah cluster 1, sehingga data tersebut dimasukkan ke dalam cluster 1. 

• Metode  k-means 
Metode  k-means memiliki  beberapa  ciri  khas  atau  karakteristik  dalam clustering data yaitu pertama k-means merupakan metode pengelompokkan yang sederhana  dan  dapat  digunakan  dengan  mudah.  Kedua,  k-means  tidak  dapat melakukan segmentasi  data dengan baik dimana hasil segmentasinya tidak dapat memberikan pola kelompok yang mewakili karakteristik bentuk alami data. Ketiga, k-means bisa mengalami masalah ketika mengelompokkan data yang mengandung outlier. 
 
• Hierarchical Clustering 
Pengelompokkan  hierarki  (Hierarchical  Clustering)  merupakan  metode analisis  pengelompokkan  yang  berusaha  untuk  membangun  sebuah  hierarki kelompok. Terdapat  dua  jenis  strategi  untuk  pengelompokkan  hierarki,  yaitu aglomeratif dan divisif.  Pengelompokkan hierarki aglomeratif merupakan metode pengelompokkan yang dengan melakukan pendekatan bottom up. Prosesnya dimulai dari masing-masing data sebagai sebuah kelompok, kemudian secara rekursif mencari kelompok terdekat sebagai  pasangan  untuk  bergabung  menjadi  satu  kelompok  yang  lebih besar. Proses tersebut diulang terus sampai membentuk sebuah pohon hierarki. Ada tiga teknik kedekatan yang digunakan dalam hierarki aglomeratif, yaitu single  linkage  atau  tautan  tunggal,  complete  linkage  atau  tautan  lengkap,  dan average linkage atau tautan rata-rata.   

• Metode Single Linkage 
Single  linkage  memberikan  hasil  bila  kelompok-kelompok  digabungkan menurut  jarak  antara  anggota-anggota  yang  terdekat  diantara  dua  kelompok. Kedekatan di antara dua kelompok ditentukan dari jarak terdekat (terkecil) di antara pasangan  dua  data  dari  dua  kelompok  yang  berbeda  atau  disebut  juga  nilai kemiripan termaksimal. Metode  single  linkage  cocok untuk menangani set data yang dalam bentuk distribusi datanya non-elips, tetapi metode ini sangat sensitif 
terhadap noise dan outlier.     

